{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41f4bcf8",
   "metadata": {
    "id": "pcanbuwJ7PUX",
    "papermill": {
     "duration": 0.004652,
     "end_time": "2024-03-17T20:17:13.072051",
     "exception": false,
     "start_time": "2024-03-17T20:17:13.067399",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Overview\n",
    "\n",
    "KerasNLP makes it very easy to create simple model pipelines at a very fast rate. In this guide we create a simple text classification pipeline from scratch including augmentation, model building etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda7d5a2",
   "metadata": {
    "id": "DmC_kCnI7VPq",
    "papermill": {
     "duration": 0.003841,
     "end_time": "2024-03-17T20:17:13.080100",
     "exception": false,
     "start_time": "2024-03-17T20:17:13.076259",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Imports & setup\n",
    "\n",
    "This tutorial requires you to have KerasNLP installed:\n",
    "\n",
    "```shell\n",
    "pip install keras-nlp\n",
    "```\n",
    "\n",
    "We begin by importing all required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd049fcb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-17T20:17:13.089936Z",
     "iopub.status.busy": "2024-03-17T20:17:13.089165Z",
     "iopub.status.idle": "2024-03-17T20:17:26.070724Z",
     "shell.execute_reply": "2024-03-17T20:17:26.069651Z"
    },
    "papermill": {
     "duration": 12.989109,
     "end_time": "2024-03-17T20:17:26.073111",
     "exception": false,
     "start_time": "2024-03-17T20:17:13.084002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-nlp in /opt/conda/lib/python3.10/site-packages (0.7.0.dev3)\r\n",
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.16.1)\r\n",
      "Requirement already satisfied: keras-core in /opt/conda/lib/python3.10/site-packages (from keras-nlp) (0.1.7)\r\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from keras-nlp) (1.4.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from keras-nlp) (1.24.3)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from keras-nlp) (21.3)\r\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from keras-nlp) (2023.8.8)\r\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras-nlp) (13.5.2)\r\n",
      "Requirement already satisfied: dm-tree in /opt/conda/lib/python3.10/site-packages (from keras-nlp) (0.1.8)\r\n",
      "Requirement already satisfied: kagglehub in /opt/conda/lib/python3.10/site-packages (from keras-nlp) (0.1.4)\r\n",
      "Requirement already satisfied: tensorflow-text in /opt/conda/lib/python3.10/site-packages (from keras-nlp) (2.13.0)\r\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\r\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.32)\r\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\r\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\r\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.39.0)\r\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\r\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\r\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (68.1.2)\r\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\r\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.2.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2023.11.17)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from kagglehub->keras-nlp) (4.66.1)\r\n",
      "Requirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras-core->keras-nlp) (0.0.7)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras-core->keras-nlp) (3.9.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->keras-nlp) (3.0.9)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras-nlp) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras-nlp) (2.16.1)\r\n",
      "Requirement already satisfied: tensorflow-hub>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-text->keras-nlp) (0.14.0)\r\n",
      "Requirement already satisfied: tensorflow<2.14,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-text->keras-nlp) (2.13.0)\r\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras-nlp) (0.1.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text->keras-nlp) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text->keras-nlp) (23.5.26)\r\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text->keras-nlp) (0.4.0)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text->keras-nlp) (0.2.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text->keras-nlp) (1.51.1)\r\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text->keras-nlp) (2.13.1)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text->keras-nlp) (16.0.6)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text->keras-nlp) (3.3.0)\r\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text->keras-nlp) (2.13.0)\r\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text->keras-nlp) (2.13.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text->keras-nlp) (2.3.0)\r\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text->keras-nlp) (4.5.0)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text->keras-nlp) (1.15.0)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text->keras-nlp) (0.34.0)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.14,>=2.13.0->tensorflow-text->keras-nlp) (0.41.2)\r\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text->keras-nlp) (2.22.0)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text->keras-nlp) (1.0.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text->keras-nlp) (3.4.4)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text->keras-nlp) (0.7.1)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text->keras-nlp) (3.0.1)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text->keras-nlp) (4.2.4)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text->keras-nlp) (0.2.7)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text->keras-nlp) (4.9)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text->keras-nlp) (1.3.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text->keras-nlp) (2.1.3)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text->keras-nlp) (0.4.8)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text->keras-nlp) (3.2.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-nlp wandb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ca2e6eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-17T20:17:26.085133Z",
     "iopub.status.busy": "2024-03-17T20:17:26.084824Z",
     "iopub.status.idle": "2024-03-17T20:17:39.819487Z",
     "shell.execute_reply": "2024-03-17T20:17:39.818706Z"
    },
    "id": "5WBE3tLKUU94",
    "papermill": {
     "duration": 13.743269,
     "end_time": "2024-03-17T20:17:39.821873",
     "exception": false,
     "start_time": "2024-03-17T20:17:26.078604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from glob import glob\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_nlp\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import *\n",
    "from keras import Sequential\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dc4c37",
   "metadata": {
    "id": "N75_5WJeok06",
    "papermill": {
     "duration": 0.00515,
     "end_time": "2024-03-17T20:17:39.832622",
     "exception": false,
     "start_time": "2024-03-17T20:17:39.827472",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data loading\n",
    "\n",
    "This guide uses the\n",
    "[Quora Insincere Questions Classification Dataset](https://www.kaggle.com/competitions/quora-insincere-questions-classification/data)\n",
    "for demonstration purposes.\n",
    "\n",
    "To get started, we first load the dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb2cf410",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-17T20:17:39.844718Z",
     "iopub.status.busy": "2024-03-17T20:17:39.844164Z",
     "iopub.status.idle": "2024-03-17T20:17:44.121882Z",
     "shell.execute_reply": "2024-03-17T20:17:44.121013Z"
    },
    "id": "HbS3wKtXUcxV",
    "outputId": "4b458f43-226f-4f43-deba-0052db9a137a",
    "papermill": {
     "duration": 4.286008,
     "end_time": "2024-03-17T20:17:44.123949",
     "exception": false,
     "start_time": "2024-03-17T20:17:39.837941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306117</th>\n",
       "      <td>ffffcc4e2331aaf1e41e</td>\n",
       "      <td>What other technical skills do you need as a c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306118</th>\n",
       "      <td>ffffd431801e5a2f4861</td>\n",
       "      <td>Does MS in ECE have good job prospects in USA ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306119</th>\n",
       "      <td>ffffd48fb36b63db010c</td>\n",
       "      <td>Is foam insulation toxic?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306120</th>\n",
       "      <td>ffffec519fa37cf60c78</td>\n",
       "      <td>How can one start a research project based on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306121</th>\n",
       "      <td>ffffed09fedb5088744a</td>\n",
       "      <td>Who wins in a battle between a Wolverine and a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1306122 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          qid  \\\n",
       "0        00002165364db923c7e6   \n",
       "1        000032939017120e6e44   \n",
       "2        0000412ca6e4628ce2cf   \n",
       "3        000042bf85aa498cd78e   \n",
       "4        0000455dfa3e01eae3af   \n",
       "...                       ...   \n",
       "1306117  ffffcc4e2331aaf1e41e   \n",
       "1306118  ffffd431801e5a2f4861   \n",
       "1306119  ffffd48fb36b63db010c   \n",
       "1306120  ffffec519fa37cf60c78   \n",
       "1306121  ffffed09fedb5088744a   \n",
       "\n",
       "                                             question_text  target  \n",
       "0        How did Quebec nationalists see their province...       0  \n",
       "1        Do you have an adopted dog, how would you enco...       0  \n",
       "2        Why does velocity affect time? Does velocity a...       0  \n",
       "3        How did Otto von Guericke used the Magdeburg h...       0  \n",
       "4        Can I convert montra helicon D to a mountain b...       0  \n",
       "...                                                    ...     ...  \n",
       "1306117  What other technical skills do you need as a c...       0  \n",
       "1306118  Does MS in ECE have good job prospects in USA ...       0  \n",
       "1306119                          Is foam insulation toxic?       0  \n",
       "1306120  How can one start a research project based on ...       0  \n",
       "1306121  Who wins in a battle between a Wolverine and a...       0  \n",
       "\n",
       "[1306122 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/kaggle/input/quora-insincere-questions-classification/train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adb59fbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-17T20:17:44.136485Z",
     "iopub.status.busy": "2024-03-17T20:17:44.136217Z",
     "iopub.status.idle": "2024-03-17T20:17:44.198816Z",
     "shell.execute_reply": "2024-03-17T20:17:44.198005Z"
    },
    "id": "g1hVyigCUn7O",
    "papermill": {
     "duration": 0.070935,
     "end_time": "2024-03-17T20:17:44.200700",
     "exception": false,
     "start_time": "2024-03-17T20:17:44.129765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = df['question_text'].tolist()\n",
    "target = df['target'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f98195f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-17T20:17:44.213519Z",
     "iopub.status.busy": "2024-03-17T20:17:44.212821Z",
     "iopub.status.idle": "2024-03-17T20:17:46.605614Z",
     "shell.execute_reply": "2024-03-17T20:17:46.604714Z"
    },
    "papermill": {
     "duration": 2.401418,
     "end_time": "2024-03-17T20:17:46.607831",
     "exception": false,
     "start_time": "2024-03-17T20:17:44.206413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "import wandb\n",
    "user_secrets = UserSecretsClient()\n",
    "secret_value_0 = user_secrets.get_secret(\"api_key\")\n",
    "wandb.login(key = secret_value_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5eb988cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-17T20:17:46.621938Z",
     "iopub.status.busy": "2024-03-17T20:17:46.621205Z",
     "iopub.status.idle": "2024-03-17T20:20:26.817828Z",
     "shell.execute_reply": "2024-03-17T20:20:26.817103Z"
    },
    "papermill": {
     "duration": 160.205788,
     "end_time": "2024-03-17T20:20:26.819897",
     "exception": false,
     "start_time": "2024-03-17T20:17:46.614109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtensorgirl\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.16.4 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20240317_201746-hqidhmcb\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfanciful-capybara-6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/tensorgirl/quora\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/tensorgirl/quora/runs/hqidhmcb\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mfanciful-capybara-6\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/tensorgirl/quora/runs/hqidhmcb\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240317_201746-hqidhmcb/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "run = wandb.init(project=\"quora\")\n",
    "table = wandb.Table(data=df)\n",
    "run.log({'data':table})\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f22bebb",
   "metadata": {
    "id": "N0EqjUZTCofa",
    "papermill": {
     "duration": 0.007081,
     "end_time": "2024-03-17T20:20:26.834245",
     "exception": false,
     "start_time": "2024-03-17T20:20:26.827164",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Building\n",
    "\n",
    "We use the pretrained `Roberta Classifier` from the KerasNLP to build a simple text classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4a0b386",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-17T20:20:26.849509Z",
     "iopub.status.busy": "2024-03-17T20:20:26.849222Z",
     "iopub.status.idle": "2024-03-17T20:28:05.640982Z",
     "shell.execute_reply": "2024-03-17T20:28:05.640001Z"
    },
    "id": "ww1txzj_YCjh",
    "outputId": "eb83a9e9-0861-4eac-8147-a8f7aaa0e916",
    "papermill": {
     "duration": 458.802726,
     "end_time": "2024-03-17T20:28:05.644006",
     "exception": false,
     "start_time": "2024-03-17T20:20:26.841280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.16.4 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20240317_202026-lvg1zh2s\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmodel_training\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/tensorgirl/quora\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/tensorgirl/quora/runs/lvg1zh2s\u001b[0m\n",
      "Attaching 'config.json' from model 'keras/roberta/keras/roberta_base_en/1' to your Kaggle notebook...\n",
      "Attaching 'config.json' from model 'keras/roberta/keras/roberta_base_en/1' to your Kaggle notebook...\n",
      "Attaching 'model.weights.h5' from model 'keras/roberta/keras/roberta_base_en/1' to your Kaggle notebook...\n",
      "Attaching 'tokenizer.json' from model 'keras/roberta/keras/roberta_base_en/1' to your Kaggle notebook...\n",
      "Attaching 'assets/tokenizer/vocabulary.json' from model 'keras/roberta/keras/roberta_base_en/1' to your Kaggle notebook...\n",
      "Attaching 'assets/tokenizer/merges.txt' from model 'keras/roberta/keras/roberta_base_en/1' to your Kaggle notebook...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 388s 1s/step - loss: 0.1720 - sparse_categorical_accuracy: 0.9382\n"
     ]
    }
   ],
   "source": [
    "from wandb.keras import WandbMetricsLogger\n",
    "run = wandb.init(project=\"quora\",name = 'model_training')\n",
    "\n",
    "classifier = keras_nlp.models.RobertaClassifier.from_preset(\n",
    "    \"roberta_base_en\",\n",
    "    num_classes=2,\n",
    ")\n",
    "classifier.backbone.trainable = False\n",
    "\n",
    "history = classifier.fit(x=text[:5000], y=target[:5000], verbose =1, epochs=1,batch_size=16,callbacks=[WandbMetricsLogger()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b28a1e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-17T20:28:05.765030Z",
     "iopub.status.busy": "2024-03-17T20:28:05.764616Z",
     "iopub.status.idle": "2024-03-17T20:28:09.943271Z",
     "shell.execute_reply": "2024-03-17T20:28:09.942569Z"
    },
    "id": "byM0Z84SksVk",
    "outputId": "4efed16f-7b00-4d54-99ec-1955afc7d44d",
    "papermill": {
     "duration": 4.218735,
     "end_time": "2024-03-17T20:28:09.945197",
     "exception": false,
     "start_time": "2024-03-17T20:28:05.726462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                       epoch/epoch ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/learning_rate ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                        epoch/loss ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: epoch/sparse_categorical_accuracy ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                       epoch/epoch 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/learning_rate 2e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                        epoch/loss 0.17204\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: epoch/sparse_categorical_accuracy 0.9382\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mmodel_training\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/tensorgirl/quora/runs/lvg1zh2s\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240317_202026-lvg1zh2s/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2d71b2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-17T20:28:10.012682Z",
     "iopub.status.busy": "2024-03-17T20:28:10.012378Z",
     "iopub.status.idle": "2024-03-17T20:28:21.013356Z",
     "shell.execute_reply": "2024-03-17T20:28:21.012450Z"
    },
    "id": "vMuEl49mkcES",
    "outputId": "9e551d45-2cd4-41d3-9298-21c7b27a570b",
    "papermill": {
     "duration": 11.037024,
     "end_time": "2024-03-17T20:28:21.015390",
     "exception": false,
     "start_time": "2024-03-17T20:28:09.978366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 8s 8s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.69298095,  0.8235075 ]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict([text[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46aabe53",
   "metadata": {
    "id": "4aECUazjnBH2",
    "papermill": {
     "duration": 0.033816,
     "end_time": "2024-03-17T20:28:21.083862",
     "exception": false,
     "start_time": "2024-03-17T20:28:21.050046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 290346,
     "sourceId": 10737,
     "sourceType": "competition"
    },
    {
     "modelInstanceId": 4703,
     "sourceId": 5930,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 674.250373,
   "end_time": "2024-03-17T20:28:23.938862",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-17T20:17:09.688489",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
